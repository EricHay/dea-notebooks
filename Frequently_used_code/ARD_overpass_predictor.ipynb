{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARD Overpass Predictor <img align=\"right\" src=\"../Supplementary_data/dea_logo.jpg\">\n",
    "\n",
    "* [**Sign up to the DEA Sandbox**](https://docs.dea.ga.gov.au/setup/sandbox.html) to run this notebook interactively from a browser\n",
    "* **Compatibility:** Notebook currently compatible with the `DEA Sandbox` environment\n",
    "* **Special requirements:** This notebook loads data from an external .csv file (`overpass_input.csv`) from the `Supplementary_data` folder of this repository\n",
    "\n",
    "\n",
    "## Background\n",
    "Knowing the time of a satellite overpass (OP) at a field site is necessary to plan field work activities. While predicting the timesteps for a single field site that receives only one overpass from a given satellite is easy, it gets more complicated when you need overpass information across multiple field sites, with sites that may lie in overlapping satellite passes. \n",
    "This notebook can be used to output a list of ordered overpasses for given field sites by providing an initial timestamp for field sites of interest. Output for multiple sites are ordered by date such that dual overpasses can be identified.\n",
    "\n",
    "Caution: manual process! You need to provide a start date + time for the overpass of the site you are interested in - go to https://nationalmap.gov.au/ and https://evdc.esa.int/orbit/ to get an overpass for your location (lat/long) and add this to the input file.\n",
    "\n",
    "See \"overpass_input.xlsx\" as an example input file - this contains a number of field sites, some with multiple overpasses in a given orbital period.\n",
    "\n",
    "## Description\n",
    "Make changes to the notebook, following the **Steps** in bold\n",
    "1. Provide an input file - this can be the example included or your own field site information\n",
    "2. Specify which field sites receive extra overpasses in an orbital period, ie those which lie in satellite imaging overlap\n",
    "3. Specify output field sites - you can select a subset of sites of interest (if adding your site to the original example file)\n",
    "4. Combine field site overpasses, need to enter these manually according to dataframe length, ie by field sites that receive most overpasses to least\n",
    "5. Specify an output file name\n",
    "\n",
    "### Load packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary tools\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - specify input file containing initial overpass data for a given site:\n",
    "\n",
    "Read in base overpass file ```overpass_input.csv``` and specify datetime formats if necessary (if you get errors or times look odd, date formatting is needed)\n",
    "\n",
    "- Input date times must be in UTC\n",
    "- Make sure the necessary dates for your site are imported correctly - should be YYYY-MM-DD HH:MM:SS in 24hr format\n",
    "- If you have weird .xlsx date formatting, pd.to_datetime can force formatting - see below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Path</th>\n",
       "      <th>Row</th>\n",
       "      <th>landsat_8</th>\n",
       "      <th>landsat_8_2</th>\n",
       "      <th>sentinel_2a</th>\n",
       "      <th>sentinel_2a_2</th>\n",
       "      <th>sentinel_2b</th>\n",
       "      <th>sentinel_2b_2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Site</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Blanchetown</th>\n",
       "      <td>-34.206</td>\n",
       "      <td>139.63000</td>\n",
       "      <td>97</td>\n",
       "      <td>84</td>\n",
       "      <td>2019-01-12 00:27:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2019-10-12 00:42:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2019-08-12 00:39:00</td>\n",
       "      <td>2019-12-11 00:49:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dharawal</th>\n",
       "      <td>-34.151</td>\n",
       "      <td>150.55320</td>\n",
       "      <td>89</td>\n",
       "      <td>84</td>\n",
       "      <td>2019-12-15 23:43:00</td>\n",
       "      <td>2019-12-08 23:44:00</td>\n",
       "      <td>2019-08-12 00:01:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2019-05-12 23:59:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dookie</th>\n",
       "      <td>-36.385</td>\n",
       "      <td>145.71899</td>\n",
       "      <td>93</td>\n",
       "      <td>85</td>\n",
       "      <td>2019-05-12 00:02:00</td>\n",
       "      <td>2019-12-13 00:03:00</td>\n",
       "      <td>2019-11-12 00:12:00</td>\n",
       "      <td>2019-12-04 00:22:00</td>\n",
       "      <td>2019-02-12 00:20:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fowlers_Gap</th>\n",
       "      <td>-31.066</td>\n",
       "      <td>141.75100</td>\n",
       "      <td>96</td>\n",
       "      <td>81</td>\n",
       "      <td>2019-10-12 00:19:00</td>\n",
       "      <td>2019-12-17 00:25:00</td>\n",
       "      <td>2019-10-12 00:41:00</td>\n",
       "      <td>2019-12-17 00:32:00</td>\n",
       "      <td>2019-12-18 00:38:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lake_George</th>\n",
       "      <td>-35.094</td>\n",
       "      <td>149.46300</td>\n",
       "      <td>90</td>\n",
       "      <td>84</td>\n",
       "      <td>2019-11-29 23:43:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2019-12-20 23:58:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2019-12-15 23:58:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lake_Lefroy</th>\n",
       "      <td>-31.342</td>\n",
       "      <td>121.64700</td>\n",
       "      <td>109</td>\n",
       "      <td>82</td>\n",
       "      <td>2019-05-12 01:40:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2019-11-12 01:52:00</td>\n",
       "      <td>2019-12-14 02:02:00</td>\n",
       "      <td>2019-12-22 01:58:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mitchell_Downs</th>\n",
       "      <td>-23.517</td>\n",
       "      <td>144.31700</td>\n",
       "      <td>96</td>\n",
       "      <td>76</td>\n",
       "      <td>2019-10-12 00:17:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2019-12-17 00:30:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2019-12-18 00:36:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mullion</th>\n",
       "      <td>-35.123</td>\n",
       "      <td>148.86200</td>\n",
       "      <td>91</td>\n",
       "      <td>84</td>\n",
       "      <td>2019-11-29 23:43:00</td>\n",
       "      <td>2019-11-20 23:49:00</td>\n",
       "      <td>2019-12-20 23:58:00</td>\n",
       "      <td>2019-12-14 00:07:00</td>\n",
       "      <td>2019-12-15 23:58:00</td>\n",
       "      <td>2019-12-19 00:07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Narrabundah</th>\n",
       "      <td>-35.334</td>\n",
       "      <td>149.14500</td>\n",
       "      <td>90</td>\n",
       "      <td>85</td>\n",
       "      <td>2019-11-29 23:43:00</td>\n",
       "      <td>2019-11-20 23:49:00</td>\n",
       "      <td>2019-12-20 23:58:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2019-12-15 23:58:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pinnacles</th>\n",
       "      <td>-30.585</td>\n",
       "      <td>115.15500</td>\n",
       "      <td>113</td>\n",
       "      <td>81</td>\n",
       "      <td>2019-08-12 02:11:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2019-12-20 02:23:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2019-12-21 02:28:00</td>\n",
       "      <td>2019-12-18 02:19:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tumbarumba</th>\n",
       "      <td>-35.657</td>\n",
       "      <td>148.15200</td>\n",
       "      <td>91</td>\n",
       "      <td>85</td>\n",
       "      <td>2019-06-12 23:50:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2019-12-18 00:03:00</td>\n",
       "      <td>2019-12-11 00:12:00</td>\n",
       "      <td>2019-12-19 00:09:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winton</th>\n",
       "      <td>-22.523</td>\n",
       "      <td>142.93700</td>\n",
       "      <td>96</td>\n",
       "      <td>76</td>\n",
       "      <td>2019-01-12 00:23:00</td>\n",
       "      <td>2019-12-25 00:22:00</td>\n",
       "      <td>2019-12-20 00:40:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2019-12-18 00:36:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Latitude  Longitude  Path  Row           landsat_8  \\\n",
       "Site                                                                 \n",
       "Blanchetown      -34.206  139.63000    97   84 2019-01-12 00:27:00   \n",
       "Dharawal         -34.151  150.55320    89   84 2019-12-15 23:43:00   \n",
       "Dookie           -36.385  145.71899    93   85 2019-05-12 00:02:00   \n",
       "Fowlers_Gap      -31.066  141.75100    96   81 2019-10-12 00:19:00   \n",
       "Lake_George      -35.094  149.46300    90   84 2019-11-29 23:43:00   \n",
       "Lake_Lefroy      -31.342  121.64700   109   82 2019-05-12 01:40:00   \n",
       "Mitchell_Downs   -23.517  144.31700    96   76 2019-10-12 00:17:00   \n",
       "Mullion          -35.123  148.86200    91   84 2019-11-29 23:43:00   \n",
       "Narrabundah      -35.334  149.14500    90   85 2019-11-29 23:43:00   \n",
       "Pinnacles        -30.585  115.15500   113   81 2019-08-12 02:11:00   \n",
       "Tumbarumba       -35.657  148.15200    91   85 2019-06-12 23:50:00   \n",
       "Winton           -22.523  142.93700    96   76 2019-01-12 00:23:00   \n",
       "\n",
       "                       landsat_8_2         sentinel_2a       sentinel_2a_2  \\\n",
       "Site                                                                         \n",
       "Blanchetown                    NaT 2019-10-12 00:42:00                 NaT   \n",
       "Dharawal       2019-12-08 23:44:00 2019-08-12 00:01:00                 NaT   \n",
       "Dookie         2019-12-13 00:03:00 2019-11-12 00:12:00 2019-12-04 00:22:00   \n",
       "Fowlers_Gap    2019-12-17 00:25:00 2019-10-12 00:41:00 2019-12-17 00:32:00   \n",
       "Lake_George                    NaT 2019-12-20 23:58:00                 NaT   \n",
       "Lake_Lefroy                    NaT 2019-11-12 01:52:00 2019-12-14 02:02:00   \n",
       "Mitchell_Downs                 NaT 2019-12-17 00:30:00                 NaT   \n",
       "Mullion        2019-11-20 23:49:00 2019-12-20 23:58:00 2019-12-14 00:07:00   \n",
       "Narrabundah    2019-11-20 23:49:00 2019-12-20 23:58:00                 NaT   \n",
       "Pinnacles                      NaT 2019-12-20 02:23:00                 NaT   \n",
       "Tumbarumba                     NaT 2019-12-18 00:03:00 2019-12-11 00:12:00   \n",
       "Winton         2019-12-25 00:22:00 2019-12-20 00:40:00                 NaT   \n",
       "\n",
       "                       sentinel_2b       sentinel_2b_2  \n",
       "Site                                                    \n",
       "Blanchetown    2019-08-12 00:39:00 2019-12-11 00:49:00  \n",
       "Dharawal       2019-05-12 23:59:00                 NaT  \n",
       "Dookie         2019-02-12 00:20:00                 NaT  \n",
       "Fowlers_Gap    2019-12-18 00:38:00                 NaT  \n",
       "Lake_George    2019-12-15 23:58:00                 NaT  \n",
       "Lake_Lefroy    2019-12-22 01:58:00                 NaT  \n",
       "Mitchell_Downs 2019-12-18 00:36:00                 NaT  \n",
       "Mullion        2019-12-15 23:58:00 2019-12-19 00:07:00  \n",
       "Narrabundah    2019-12-15 23:58:00                 NaT  \n",
       "Pinnacles      2019-12-21 02:28:00 2019-12-18 02:19:00  \n",
       "Tumbarumba     2019-12-19 00:09:00                 NaT  \n",
       "Winton         2019-12-18 00:36:00                 NaT  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in base file, must specify datetimes for those columns which aren't already in datetime format.\n",
    "# An example file, 'overpass_input.csv' is provided. \n",
    "# Edit this file with new field sites, or load your own file with field sites as needed.\n",
    "\n",
    "os.chdir('/home/jovyan/Supplementary_data/ARD_overpass_predictor/')  # change directory to location of input example file. \n",
    "overpass = pd.read_csv('overpass_input.csv', index_col='Site') # read in example file 'overpass_input.csv'\n",
    "\n",
    "# Format date time for each field site. Secondary overpasses also need to be specified. Ie 1st L8 OP = \"landsat_8\", \n",
    "# second L8 OP = \"landsat_8_2\" and so on\n",
    "overpass['landsat_8'] = pd.to_datetime(overpass.landsat_8)\n",
    "overpass['sentinel_2a'] = pd.to_datetime(overpass.sentinel_2a)\n",
    "overpass['sentinel_2b'] = pd.to_datetime(overpass.sentinel_2b)\n",
    "overpass['landsat_8_2'] = pd.to_datetime(overpass.landsat_8_2, dayfirst=True, format='%d/%m/%Y %H:%M')\n",
    "overpass['sentinel_2a_2'] = pd.to_datetime(overpass.sentinel_2a_2, dayfirst=True, format='%d/%m/%Y %H:%M')\n",
    "overpass['sentinel_2b_2'] = pd.to_datetime(overpass.sentinel_2b_2, dayfirst=True, format='%d/%m/%Y %H:%M')\n",
    "\n",
    "overpass\n",
    "# overpass = base file - check if sensible. \"NaT\" values are expected - indicates a date was not entered in input file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set satellite timesteps for overpasses, calculated from https://evdc.esa.int/orbit/\n",
    "# Depending on your application, you may want to add more accurate timesteps - these are hashed out as rough times are ok\n",
    "\n",
    "l8_timestep = datetime.timedelta (days=16) #(days=15,hours=23,minutes=59,seconds=37)\n",
    "s2a_timestep = datetime.timedelta (days=10) #(days=10,hours=0,minutes=1,seconds=10)\n",
    "s2b_timestep = datetime.timedelta (days=10) #(days=10,hours=0,minutes=1,seconds=47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Site\n",
       "Blanchetown                      NaT\n",
       "Dharawal                         NaT\n",
       "Dookie           2019-12-04 00:22:00\n",
       "Fowlers_Gap      2019-12-17 00:32:00\n",
       "Lake_George                      NaT\n",
       "Lake_Lefroy      2019-12-14 02:02:00\n",
       "Mitchell_Downs                   NaT\n",
       "Mullion          2019-12-14 00:07:00\n",
       "Narrabundah                      NaT\n",
       "Pinnacles                        NaT\n",
       "Tumbarumba       2019-12-11 00:12:00\n",
       "Winton                           NaT\n",
       "Name: sentinel_2a_2, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify start date\n",
    "\n",
    "l8_startdate = overpass['landsat_8'] \n",
    "l8_startdate_2 = overpass['landsat_8_2'] \n",
    "sentinel2a_startdate = overpass['sentinel_2a']\n",
    "sentinel2a_2_startdate = overpass['sentinel_2a_2']\n",
    "sentinel2b_startdate = overpass['sentinel_2b']\n",
    "sentinel2b_2_startdate = overpass['sentinel_2b_2']\n",
    "sentinel2a_2_startdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Landsat 8 overpass prediction for 20 * the overpass frequency - ie 20*l8_timestep = 320 days\n",
    "\n",
    "landsat = list()\n",
    "for i in range(20):\n",
    "    landsat.append(l8_startdate + l8_timestep*(i))\n",
    "\n",
    "landsat = pd.DataFrame(landsat)\n",
    "#landsat = landsat + datetime.timedelta(hours=10) #convert to local time (Aus eastern standard time) = utc + 10 hours\n",
    "#landsat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sentinel 2a overpass prediction for 32 * the overpass frequency, this is to give a similar total time to the L8 prediction\n",
    "\n",
    "Sentinel_2A = []  \n",
    "for i in range(32):\n",
    "    Sentinel_2A.append(sentinel2a_startdate + s2a_timestep * (i))\n",
    "    \n",
    "Sentinel_2A = pd.DataFrame(Sentinel_2A)\n",
    "#Sentinel_2A = Sentinel_2A + datetime.timedelta(hours=10) #convert to local time (Aus eastern standard time) = utc + 10 hours\n",
    "#Sentinel_2A  ### to AEDT, add 11h not 10 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sentinel 2b\n",
    "\n",
    "Sentinel_2B = []\n",
    "for i in range(32):\n",
    "    Sentinel_2B.append(sentinel2b_startdate + s2b_timestep * (i))\n",
    "    \n",
    "Sentinel_2B = pd.DataFrame(Sentinel_2B)\n",
    "#Sentinel_2B = Sentinel_2B + datetime.timedelta(hours=10) #convert to local time (Aus eastern standard time) = utc + 10 hours\n",
    "#Sentinel_2B  ### to AEDT, add 11h not 10 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Landasat_2\n",
    "# Prediction for L8 overpasses at sites which are covered by more than 1 overpass in a 16-day period.\n",
    "# These sites are Dharawal, Dookie, Fowlers_Gap, Mullion & Winton \n",
    "\n",
    "landsat_2 = []\n",
    "for i in range(20):\n",
    "    landsat_2.append(l8_startdate_2 + l8_timestep*(i))\n",
    "\n",
    "landsat_2 = pd.DataFrame(landsat_2)\n",
    "#landsat_2 = landsat_2 + datetime.timedelta(hours=10)\n",
    "#landsat_2  ### to AEDT, add 11h not 10 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sentinel_2A_2\n",
    "# Sentinel 2a secondary (Dookie, Fowlers_Gap, Lake_Lefroy, Mullion, Tumbarumba)\n",
    "\n",
    "Sentinel_2A_2 = []  \n",
    "for i in range(32):\n",
    "    Sentinel_2A_2.append(sentinel2a_2_startdate + s2a_timestep * (i))\n",
    "    \n",
    "Sentinel_2A_2 = pd.DataFrame(Sentinel_2A_2)\n",
    "#Sentinel_2A_2 = Sentinel_2A_2 + datetime.timedelta(hours=10)\n",
    "#Sentinel_2A_2  ### to AEDT, add 11h not 10 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sentinel_2B_2\n",
    "# Sentinel 2b secondary (Blanchetown, Lake_George, Narrabundah, Pinnacles)\n",
    "\n",
    "Sentinel_2B_2 = []\n",
    "for i in range(32):\n",
    "    Sentinel_2B_2.append(sentinel2b_2_startdate + s2b_timestep * (i))\n",
    "    \n",
    "Sentinel_2B_2 = pd.DataFrame(Sentinel_2B_2)\n",
    "#Sentinel_2B_2 = Sentinel_2B_2 + datetime.timedelta(hours=10)\n",
    "#Sentinel_2B_2  ### to AEDT, add 11h not 10 ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - for sites that recieve more than 1 OP in an orbital period, these must be appended to the dataframe.\n",
    "- You must also specify the field site that this happens first for, for each satellite. ie the field site \"Narrabundah\" is the first to have an extra L8 OP (actually in the same path as Mullion, -> can use whichever site). This is evident from your input file. See the e.g file \"overpass_input.xlsx\"\n",
    "\n",
    "#### Edit the following 3 cells appropriately, altering the .sort_values(by='field_site')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Combine Landsat 8 data (base plus extra overpasses)\n",
    "\n",
    "L8_combined2 = landsat.append(landsat_2)\n",
    "drop_label_L8 = L8_combined2.reset_index(drop=True)\n",
    "L8_combined2 = drop_label_L8.sort_values(by='Narrabundah') # specify first site which gets extra OP's to sort by\n",
    "L8_combined2.index.names = ['Landsat_8']\n",
    "#L8_combined2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Combine Sentinel 2A data (base plus extra overpasses)\n",
    "\n",
    "S2A_combined = Sentinel_2A.append(Sentinel_2A_2)\n",
    "drop_label_S2A = S2A_combined.reset_index(drop=True)\n",
    "S2A_combined = drop_label_S2A.sort_values(by='Mullion') # specify first site which gets extra OP's to sort by\n",
    "S2A_combined.index.names = ['Sentinel_2A']\n",
    "#S2A_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Combine Sentinel 2B data (base plus extra overpasses)\n",
    "\n",
    "S2B_combined = Sentinel_2B.append(Sentinel_2B_2)\n",
    "drop_label_S2B = S2B_combined.reset_index(drop=True)\n",
    "S2B_combined = drop_label_S2B.sort_values(by='Mullion') # specify first site which gets extra OP's to sort by\n",
    "S2B_combined.index.names = ['Sentinel_2B']\n",
    "#S2B_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "S2A_combined['Sat'] = 'S2A'\n",
    "S2B_combined['Sat'] = 'S2B'\n",
    "L8_combined2['Sat'] = 'L8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined1 = S2B_combined.append(S2A_combined)\n",
    "combined = combined1.append(L8_combined2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add time dummy - timestep every 2 days to order data by. This allows the output to be ordered in a sensible, human-readable way\n",
    "timedummy = []\n",
    "t0 = datetime.date(2019, 11, 1)\n",
    "dummystep = datetime.timedelta(days=2)\n",
    "\n",
    "for i in range(300):\n",
    "    timedummy.append(t0 + dummystep * (i))\n",
    "    \n",
    "timedummy = pd.DataFrame(timedummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Site</th>\n",
       "      <th>Blanchetown</th>\n",
       "      <th>Dharawal</th>\n",
       "      <th>Dookie</th>\n",
       "      <th>Fowlers_Gap</th>\n",
       "      <th>Lake_George</th>\n",
       "      <th>Lake_Lefroy</th>\n",
       "      <th>Mitchell_Downs</th>\n",
       "      <th>Mullion</th>\n",
       "      <th>Narrabundah</th>\n",
       "      <th>Pinnacles</th>\n",
       "      <th>Tumbarumba</th>\n",
       "      <th>Winton</th>\n",
       "      <th>Sat</th>\n",
       "      <th>DateStep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-08-12 00:39:00</td>\n",
       "      <td>2019-05-12 23:59:00</td>\n",
       "      <td>2019-02-12 00:20:00</td>\n",
       "      <td>2019-12-18 00:38:00</td>\n",
       "      <td>2019-12-15 23:58:00</td>\n",
       "      <td>2019-12-22 01:58:00</td>\n",
       "      <td>2019-12-18 00:36:00</td>\n",
       "      <td>2019-12-15 23:58:00</td>\n",
       "      <td>2019-12-15 23:58:00</td>\n",
       "      <td>2019-12-21 02:28:00</td>\n",
       "      <td>2019-12-19 00:09:00</td>\n",
       "      <td>2019-12-18 00:36:00</td>\n",
       "      <td>S2B</td>\n",
       "      <td>2019-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2019-12-11 00:49:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2019-12-19 00:07:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2019-12-18 02:19:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>S2B</td>\n",
       "      <td>2020-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-22 00:39:00</td>\n",
       "      <td>2019-05-22 23:59:00</td>\n",
       "      <td>2019-02-22 00:20:00</td>\n",
       "      <td>2019-12-28 00:38:00</td>\n",
       "      <td>2019-12-25 23:58:00</td>\n",
       "      <td>2020-01-01 01:58:00</td>\n",
       "      <td>2019-12-28 00:36:00</td>\n",
       "      <td>2019-12-25 23:58:00</td>\n",
       "      <td>2019-12-25 23:58:00</td>\n",
       "      <td>2019-12-31 02:28:00</td>\n",
       "      <td>2019-12-29 00:09:00</td>\n",
       "      <td>2019-12-28 00:36:00</td>\n",
       "      <td>S2B</td>\n",
       "      <td>2019-11-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2019-12-21 00:49:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2019-12-29 00:07:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2019-12-28 02:19:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>S2B</td>\n",
       "      <td>2020-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-09-01 00:39:00</td>\n",
       "      <td>2019-06-01 23:59:00</td>\n",
       "      <td>2019-03-04 00:20:00</td>\n",
       "      <td>2020-01-07 00:38:00</td>\n",
       "      <td>2020-01-04 23:58:00</td>\n",
       "      <td>2020-01-11 01:58:00</td>\n",
       "      <td>2020-01-07 00:36:00</td>\n",
       "      <td>2020-01-04 23:58:00</td>\n",
       "      <td>2020-01-04 23:58:00</td>\n",
       "      <td>2020-01-10 02:28:00</td>\n",
       "      <td>2020-01-08 00:09:00</td>\n",
       "      <td>2020-01-07 00:36:00</td>\n",
       "      <td>S2B</td>\n",
       "      <td>2019-11-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Site         Blanchetown            Dharawal              Dookie  \\\n",
       "0    2019-08-12 00:39:00 2019-05-12 23:59:00 2019-02-12 00:20:00   \n",
       "32   2019-12-11 00:49:00                 NaT                 NaT   \n",
       "1    2019-08-22 00:39:00 2019-05-22 23:59:00 2019-02-22 00:20:00   \n",
       "33   2019-12-21 00:49:00                 NaT                 NaT   \n",
       "2    2019-09-01 00:39:00 2019-06-01 23:59:00 2019-03-04 00:20:00   \n",
       "\n",
       "Site         Fowlers_Gap         Lake_George         Lake_Lefroy  \\\n",
       "0    2019-12-18 00:38:00 2019-12-15 23:58:00 2019-12-22 01:58:00   \n",
       "32                   NaT                 NaT                 NaT   \n",
       "1    2019-12-28 00:38:00 2019-12-25 23:58:00 2020-01-01 01:58:00   \n",
       "33                   NaT                 NaT                 NaT   \n",
       "2    2020-01-07 00:38:00 2020-01-04 23:58:00 2020-01-11 01:58:00   \n",
       "\n",
       "Site      Mitchell_Downs             Mullion         Narrabundah  \\\n",
       "0    2019-12-18 00:36:00 2019-12-15 23:58:00 2019-12-15 23:58:00   \n",
       "32                   NaT 2019-12-19 00:07:00                 NaT   \n",
       "1    2019-12-28 00:36:00 2019-12-25 23:58:00 2019-12-25 23:58:00   \n",
       "33                   NaT 2019-12-29 00:07:00                 NaT   \n",
       "2    2020-01-07 00:36:00 2020-01-04 23:58:00 2020-01-04 23:58:00   \n",
       "\n",
       "Site           Pinnacles          Tumbarumba              Winton  Sat  \\\n",
       "0    2019-12-21 02:28:00 2019-12-19 00:09:00 2019-12-18 00:36:00  S2B   \n",
       "32   2019-12-18 02:19:00                 NaT                 NaT  S2B   \n",
       "1    2019-12-31 02:28:00 2019-12-29 00:09:00 2019-12-28 00:36:00  S2B   \n",
       "33   2019-12-28 02:19:00                 NaT                 NaT  S2B   \n",
       "2    2020-01-10 02:28:00 2020-01-08 00:09:00 2020-01-07 00:36:00  S2B   \n",
       "\n",
       "Site    DateStep  \n",
       "0     2019-11-01  \n",
       "32    2020-01-04  \n",
       "1     2019-11-03  \n",
       "33    2020-01-06  \n",
       "2     2019-11-05  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['DateStep'] = timedummy\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - select the field sites you want to output. \n",
    "For new field sites, comment \"#\" out the old, add the new in the same format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new df for each field site of interest. To add a new field site, add in same format ie \n",
    "# \"Field_Site = df[['Field_Site', 'Sat', 'DateStep']].copy()\"\n",
    "\n",
    "#Blanchetown = df[['Blanchetown', 'Satellite', 'DateStep']].copy()\n",
    "#Dharawal = df[['Dharawal', 'Satellite', 'DateStep']].copy()\n",
    "#Dookie = df[['Dookie', 'Satellite', 'DateStep']].copy()\n",
    "#Fowlers_Gap = df[['Fowlers_Gap', 'Satellite', 'DateStep']].copy()\n",
    "Lake_George = df[['Lake_George', 'Sat', 'DateStep']].copy()\n",
    "#Lake_Lefroy = df[['Lake_Lefroy', 'Satellite', 'DateStep']].copy()\n",
    "#Mitchell_Downs = df[['Mitchell_Downs', 'Satellite', 'DateStep']].copy()\n",
    "Mullion = df[['Mullion', 'Sat', 'DateStep']].copy()\n",
    "Narrabundah = df[['Narrabundah', 'Sat', 'DateStep']].copy()\n",
    "#Pinnacles = df[['Pinnacles', 'Satellite', 'DateStep']].copy()\n",
    "Tumbarumba = df[['Tumbarumba', 'Sat', 'DateStep']].copy()\n",
    "#Winton = df[['Winton', 'Satellite', 'DateStep']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder by date for each site, include satellite tags for each date\n",
    "\n",
    "#Blanchetown = Blanchetown.sort_values(by=['Blanchetown', 'DateStep'])\n",
    "#Dharawal = Dharawal.sort_values(by=['Dharawal', 'DateStep'])\n",
    "#Dookie = Dookie.sort_values(by=['Dookie', 'DateStep'])\n",
    "#Fowlers_Gap = Fowlers_Gap.sort_values(by=['Fowlers_Gap', 'DateStep'])\n",
    "Lake_George = Lake_George.sort_values(by=['Lake_George', 'DateStep'])\n",
    "#Lake_Lefroy = Lake_Lefroy.sort_values(by=['Lake_Lefroy', 'DateStep'])\n",
    "#Mitchell_Downs = Mitchell_Downs.sort_values(by=['Mitchell_Downs', 'DateStep'])\n",
    "Mullion = Mullion.sort_values(by=['Mullion', 'DateStep'])\n",
    "Narrabundah = Narrabundah.sort_values(by=['Narrabundah', 'DateStep'])\n",
    "#Pinnacles = Pinnacles.sort_values(by=['Pinnacles', 'DateStep'])\n",
    "Tumbarumba = Tumbarumba.sort_values(by=['Tumbarumba', 'DateStep'])\n",
    "#Winton = Winton.sort_values(by=['Winton', 'DateStep'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Site</th>\n",
       "      <th>Lake_George</th>\n",
       "      <th>Sat</th>\n",
       "      <th>DateStep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-11-29 23:43:00</td>\n",
       "      <td>L8</td>\n",
       "      <td>2019-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-12-15 23:43:00</td>\n",
       "      <td>L8</td>\n",
       "      <td>2019-11-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-12-15 23:58:00</td>\n",
       "      <td>S2B</td>\n",
       "      <td>2019-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-12-20 23:58:00</td>\n",
       "      <td>S2A</td>\n",
       "      <td>2019-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-12-25 23:58:00</td>\n",
       "      <td>S2B</td>\n",
       "      <td>2019-11-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Site         Lake_George  Sat    DateStep\n",
       "0    2019-11-29 23:43:00   L8  2019-11-01\n",
       "1    2019-12-15 23:43:00   L8  2019-11-03\n",
       "0    2019-12-15 23:58:00  S2B  2019-11-01\n",
       "0    2019-12-20 23:58:00  S2A  2019-11-01\n",
       "1    2019-12-25 23:58:00  S2B  2019-11-03"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that ordering is sensible\n",
    "\n",
    "Lake_George.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - output individual field site.\n",
    "- if you wish to output multiple field sites, skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell to ouput an individual field site\n",
    "\n",
    "# Write individual site to excel:\n",
    "\n",
    "#Blanchetown.to_excel('Blanchetown_2020.xlsx')\n",
    "#Dharawal.to_excel('Dharawal_2020.xlsx')\n",
    "#Dookie.to_excel('Dookie_2020.xlsx')\n",
    "#Fowlers_Gap.to_excel('Fowlers_Gap_2020.xlsx')\n",
    "#Lake_George.to_excel('Lake_George_2020.xlsx')\n",
    "#Lake_Lefroy.to_excel('Lake_Lefroy_2020.xlsx')\n",
    "#Mitchell_Downs.to_excel('Mitchell_Downs_2020.xlsx')\n",
    "#Mullion.to_excel('Mullion_2020.xlsx')\n",
    "#Narrabundah.to_excel('Narrabundah_2020.xlsx')\n",
    "#Pinnacles.to_excel('Pinnacles_2020.xlsx')\n",
    "#Tumbarumba.to_excel('Tumbarumba_2020.xlsx')\n",
    "#Winton.to_excel('Winton_2020.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 - order combined dataset\n",
    "\n",
    "- Make sure to have the site with most rows first! Otherwise the data wil be 'squished' by the shorter column when merging\n",
    "- This shouold be the site with most overpasses, ie the most rows populated in the input file. For the supplied \"overpass_input.xlsx\" this is the \"Mullion\" field site\n",
    "- Follow this process to append each dataset - in this example we are interested in 4 field sites - Lake George, Mullion, Narrabundah and Tumbarumba. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Site</th>\n",
       "      <th>Mullion</th>\n",
       "      <th>Sat_x</th>\n",
       "      <th>DateStep_x</th>\n",
       "      <th>Lake_George</th>\n",
       "      <th>Sat_y</th>\n",
       "      <th>DateStep_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-11-20 23:49:00</td>\n",
       "      <td>L8</td>\n",
       "      <td>2019-12-11</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-29 23:43:00</td>\n",
       "      <td>L8</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>2019-11-29 23:43:00</td>\n",
       "      <td>L8</td>\n",
       "      <td>2019-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-12-06 23:49:00</td>\n",
       "      <td>L8</td>\n",
       "      <td>2019-12-13</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-12-14 00:07:00</td>\n",
       "      <td>S2A</td>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-12-15 23:43:00</td>\n",
       "      <td>L8</td>\n",
       "      <td>2019-11-03</td>\n",
       "      <td>2019-12-15 23:43:00</td>\n",
       "      <td>L8</td>\n",
       "      <td>2019-11-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Site             Mullion Sat_x  DateStep_x         Lake_George Sat_y  \\\n",
       "0    2019-11-20 23:49:00    L8  2019-12-11                 NaT   NaN   \n",
       "1    2019-11-29 23:43:00    L8  2019-11-01 2019-11-29 23:43:00    L8   \n",
       "2    2019-12-06 23:49:00    L8  2019-12-13                 NaT   NaN   \n",
       "3    2019-12-14 00:07:00   S2A  2020-01-04                 NaT   NaN   \n",
       "4    2019-12-15 23:43:00    L8  2019-11-03 2019-12-15 23:43:00    L8   \n",
       "\n",
       "Site  DateStep_y  \n",
       "0            NaN  \n",
       "1     2019-11-01  \n",
       "2            NaN  \n",
       "3            NaN  \n",
       "4     2019-11-03  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mullion has the most overpasses so is the longest dataset and goes first. Choose a shorter dataset to merge right on. \n",
    "# \"Lake_George\" has much fewer OP's so use this. \n",
    "merged = pd.merge(left=Mullion,right=Lake_George, how='outer',left_on='Mullion', right_on='Lake_George')\n",
    "merged.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Site</th>\n",
       "      <th>Mullion</th>\n",
       "      <th>Sat_x</th>\n",
       "      <th>DateStep_x</th>\n",
       "      <th>Lake_George</th>\n",
       "      <th>Sat_y</th>\n",
       "      <th>DateStep_y</th>\n",
       "      <th>Narrabundah</th>\n",
       "      <th>Sat</th>\n",
       "      <th>DateStep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-11-20 23:49:00</td>\n",
       "      <td>L8</td>\n",
       "      <td>2019-12-11</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-11-20 23:49:00</td>\n",
       "      <td>L8</td>\n",
       "      <td>2019-12-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-29 23:43:00</td>\n",
       "      <td>L8</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>2019-11-29 23:43:00</td>\n",
       "      <td>L8</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>2019-11-29 23:43:00</td>\n",
       "      <td>L8</td>\n",
       "      <td>2019-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-12-06 23:49:00</td>\n",
       "      <td>L8</td>\n",
       "      <td>2019-12-13</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-12-06 23:49:00</td>\n",
       "      <td>L8</td>\n",
       "      <td>2019-12-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-12-14 00:07:00</td>\n",
       "      <td>S2A</td>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-12-15 23:43:00</td>\n",
       "      <td>L8</td>\n",
       "      <td>2019-11-03</td>\n",
       "      <td>2019-12-15 23:43:00</td>\n",
       "      <td>L8</td>\n",
       "      <td>2019-11-03</td>\n",
       "      <td>2019-12-15 23:43:00</td>\n",
       "      <td>L8</td>\n",
       "      <td>2019-11-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Site             Mullion Sat_x  DateStep_x         Lake_George Sat_y  \\\n",
       "0    2019-11-20 23:49:00    L8  2019-12-11                 NaT   NaN   \n",
       "1    2019-11-29 23:43:00    L8  2019-11-01 2019-11-29 23:43:00    L8   \n",
       "2    2019-12-06 23:49:00    L8  2019-12-13                 NaT   NaN   \n",
       "3    2019-12-14 00:07:00   S2A  2020-01-04                 NaT   NaN   \n",
       "4    2019-12-15 23:43:00    L8  2019-11-03 2019-12-15 23:43:00    L8   \n",
       "\n",
       "Site  DateStep_y         Narrabundah  Sat    DateStep  \n",
       "0            NaN 2019-11-20 23:49:00   L8  2019-12-11  \n",
       "1     2019-11-01 2019-11-29 23:43:00   L8  2019-11-01  \n",
       "2            NaN 2019-12-06 23:49:00   L8  2019-12-13  \n",
       "3            NaN                 NaT  NaN         NaN  \n",
       "4     2019-11-03 2019-12-15 23:43:00   L8  2019-11-03  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_2 = pd.merge(left=merged,right=Narrabundah, how='outer',left_on='Mullion', right_on='Narrabundah')\n",
    "merged_2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Site</th>\n",
       "      <th>Mullion</th>\n",
       "      <th>Sat_x</th>\n",
       "      <th>DateStep_x</th>\n",
       "      <th>Lake_George</th>\n",
       "      <th>Sat_y</th>\n",
       "      <th>DateStep_y</th>\n",
       "      <th>Narrabundah</th>\n",
       "      <th>Sat_x</th>\n",
       "      <th>DateStep_x</th>\n",
       "      <th>Tumbarumba</th>\n",
       "      <th>Sat_y</th>\n",
       "      <th>DateStep_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-11-20 23:49:00</td>\n",
       "      <td>L8</td>\n",
       "      <td>2019-12-11</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-11-20 23:49:00</td>\n",
       "      <td>L8</td>\n",
       "      <td>2019-12-11</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-29 23:43:00</td>\n",
       "      <td>L8</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>2019-11-29 23:43:00</td>\n",
       "      <td>L8</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>2019-11-29 23:43:00</td>\n",
       "      <td>L8</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-12-06 23:49:00</td>\n",
       "      <td>L8</td>\n",
       "      <td>2019-12-13</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-12-06 23:49:00</td>\n",
       "      <td>L8</td>\n",
       "      <td>2019-12-13</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-12-14 00:07:00</td>\n",
       "      <td>S2A</td>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-12-15 23:43:00</td>\n",
       "      <td>L8</td>\n",
       "      <td>2019-11-03</td>\n",
       "      <td>2019-12-15 23:43:00</td>\n",
       "      <td>L8</td>\n",
       "      <td>2019-11-03</td>\n",
       "      <td>2019-12-15 23:43:00</td>\n",
       "      <td>L8</td>\n",
       "      <td>2019-11-03</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-12-15 23:58:00</td>\n",
       "      <td>S2B</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>2019-12-15 23:58:00</td>\n",
       "      <td>S2B</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>2019-12-15 23:58:00</td>\n",
       "      <td>S2B</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-12-19 00:07:00</td>\n",
       "      <td>S2B</td>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-12-20 23:58:00</td>\n",
       "      <td>S2A</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>2019-12-20 23:58:00</td>\n",
       "      <td>S2A</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>2019-12-20 23:58:00</td>\n",
       "      <td>S2A</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-12-22 23:49:00</td>\n",
       "      <td>L8</td>\n",
       "      <td>2019-12-15</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-12-22 23:49:00</td>\n",
       "      <td>L8</td>\n",
       "      <td>2019-12-15</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-12-24 00:07:00</td>\n",
       "      <td>S2A</td>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Site             Mullion Sat_x  DateStep_x         Lake_George Sat_y  \\\n",
       "0    2019-11-20 23:49:00    L8  2019-12-11                 NaT   NaN   \n",
       "1    2019-11-29 23:43:00    L8  2019-11-01 2019-11-29 23:43:00    L8   \n",
       "2    2019-12-06 23:49:00    L8  2019-12-13                 NaT   NaN   \n",
       "3    2019-12-14 00:07:00   S2A  2020-01-04                 NaT   NaN   \n",
       "4    2019-12-15 23:43:00    L8  2019-11-03 2019-12-15 23:43:00    L8   \n",
       "5    2019-12-15 23:58:00   S2B  2019-11-01 2019-12-15 23:58:00   S2B   \n",
       "6    2019-12-19 00:07:00   S2B  2020-01-04                 NaT   NaN   \n",
       "7    2019-12-20 23:58:00   S2A  2019-11-01 2019-12-20 23:58:00   S2A   \n",
       "8    2019-12-22 23:49:00    L8  2019-12-15                 NaT   NaN   \n",
       "9    2019-12-24 00:07:00   S2A  2020-01-06                 NaT   NaN   \n",
       "\n",
       "Site  DateStep_y         Narrabundah Sat_x  DateStep_x Tumbarumba Sat_y  \\\n",
       "0            NaN 2019-11-20 23:49:00    L8  2019-12-11        NaT   NaN   \n",
       "1     2019-11-01 2019-11-29 23:43:00    L8  2019-11-01        NaT   NaN   \n",
       "2            NaN 2019-12-06 23:49:00    L8  2019-12-13        NaT   NaN   \n",
       "3            NaN                 NaT   NaN         NaN        NaT   NaN   \n",
       "4     2019-11-03 2019-12-15 23:43:00    L8  2019-11-03        NaT   NaN   \n",
       "5     2019-11-01 2019-12-15 23:58:00   S2B  2019-11-01        NaT   NaN   \n",
       "6            NaN                 NaT   NaN         NaN        NaT   NaN   \n",
       "7     2019-11-01 2019-12-20 23:58:00   S2A  2019-11-01        NaT   NaN   \n",
       "8            NaN 2019-12-22 23:49:00    L8  2019-12-15        NaT   NaN   \n",
       "9            NaN                 NaT   NaN         NaN        NaT   NaN   \n",
       "\n",
       "Site DateStep_y  \n",
       "0           NaN  \n",
       "1           NaN  \n",
       "2           NaN  \n",
       "3           NaN  \n",
       "4           NaN  \n",
       "5           NaN  \n",
       "6           NaN  \n",
       "7           NaN  \n",
       "8           NaN  \n",
       "9           NaN  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_3 = pd.merge(left=merged_2,right=Tumbarumba, how='outer',left_on='Mullion', right_on='Tumbarumba')\n",
    "# Need to have left / right keys match to merge\n",
    "merged_3.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_3.drop('DateStep_x', axis=1, inplace=True)\n",
    "merged_3.drop('DateStep_y', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Site</th>\n",
       "      <th>Mullion</th>\n",
       "      <th>Sat_x</th>\n",
       "      <th>Lake_George</th>\n",
       "      <th>Sat_y</th>\n",
       "      <th>Narrabundah</th>\n",
       "      <th>Sat_x</th>\n",
       "      <th>Tumbarumba</th>\n",
       "      <th>Sat_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-11-20 23:49:00</td>\n",
       "      <td>L8</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-11-20 23:49:00</td>\n",
       "      <td>L8</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-29 23:43:00</td>\n",
       "      <td>L8</td>\n",
       "      <td>2019-11-29 23:43:00</td>\n",
       "      <td>L8</td>\n",
       "      <td>2019-11-29 23:43:00</td>\n",
       "      <td>L8</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-12-06 23:49:00</td>\n",
       "      <td>L8</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-12-06 23:49:00</td>\n",
       "      <td>L8</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-12-14 00:07:00</td>\n",
       "      <td>S2A</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-12-15 23:43:00</td>\n",
       "      <td>L8</td>\n",
       "      <td>2019-12-15 23:43:00</td>\n",
       "      <td>L8</td>\n",
       "      <td>2019-12-15 23:43:00</td>\n",
       "      <td>L8</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Site             Mullion Sat_x         Lake_George Sat_y         Narrabundah  \\\n",
       "0    2019-11-20 23:49:00    L8                 NaT   NaN 2019-11-20 23:49:00   \n",
       "1    2019-11-29 23:43:00    L8 2019-11-29 23:43:00    L8 2019-11-29 23:43:00   \n",
       "2    2019-12-06 23:49:00    L8                 NaT   NaN 2019-12-06 23:49:00   \n",
       "3    2019-12-14 00:07:00   S2A                 NaT   NaN                 NaT   \n",
       "4    2019-12-15 23:43:00    L8 2019-12-15 23:43:00    L8 2019-12-15 23:43:00   \n",
       "\n",
       "Site Sat_x Tumbarumba Sat_y  \n",
       "0       L8        NaT   NaN  \n",
       "1       L8        NaT   NaN  \n",
       "2       L8        NaT   NaN  \n",
       "3      NaN        NaT   NaN  \n",
       "4       L8        NaT   NaN  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_3.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6 - specify output file name\n",
    "- Insert desired file name below\n",
    "- Check output above that the predictor has worked. Days should match between sites, with gaps inserted as \"NaT\"\n",
    "- This allows dual overpasses to be identified, across and within field sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_3.to_csv('combined_UTC_OP.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Additional information\n",
    "\n",
    "**License:** The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "Digital Earth Australia data is licensed under the [Creative Commons by Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "**Contact:** If you need assistance, please post a question on the [Open Data Cube Slack channel](http://slack.opendatacube.org/) or on the [GIS Stack Exchange](https://gis.stackexchange.com/questions/ask?tags=open-data-cube) using the `open-data-cube` tag (you can view previously asked questions [here](https://gis.stackexchange.com/questions/tagged/open-data-cube)).\n",
    "If you would like to report an issue with this notebook, you can file one on [Github](https://github.com/GeoscienceAustralia/dea-notebooks).\n",
    "\n",
    "**Last modified:** Dec 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tags**: :index:`sentinel 2`, :index:`landsat 8`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
